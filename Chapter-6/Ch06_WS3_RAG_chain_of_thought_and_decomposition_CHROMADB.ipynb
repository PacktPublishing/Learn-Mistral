{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Joq7ORdChec4",
      "metadata": {
        "id": "Joq7ORdChec4"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df89be8f-2c49-4f4f-9503-2bff0b08a67a",
      "metadata": {
        "collapsed": true,
        "id": "df89be8f-2c49-4f4f-9503-2bff0b08a67a"
      },
      "outputs": [],
      "source": [
        "! pip install langchain_community langchain_mistralai langchainhub langchain tiktoken chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5258de38-0cc0-4d9d-a5ca-6e750ebe6976",
      "metadata": {
        "id": "5258de38-0cc0-4d9d-a5ca-6e750ebe6976"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY'] = '<your LangChain API KEY goes here>'\n",
        "os.environ['MISTRAL_API_KEY'] = '<your Mistral API KEY goes here>'\n",
        "os.environ['HF_TOKEN'] = '<your Hugging Face TOKEN goes here>'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ewAi5bmohmgP",
      "metadata": {
        "id": "ewAi5bmohmgP"
      },
      "outputs": [],
      "source": [
        "questions = [ \"What does Moby Dick say about humanity's struggle against nature?\",\n",
        "              \"How does Moby Dick explore the theme of obsession through Ahab's quest?\",\n",
        "              \"How is Captain Ahab portrayed as both a hero and a villain in Moby Dick?\",\n",
        "              # \"What motivates Ishmael to join the Pequod, and how does he change throughout the novel?\",\n",
        "              # \"What does the white whale symbolize in Moby Dick, and how does it relate to Ahab's obsession?\",\n",
        "              # \"How does the novel Moby Dick use the ocean as a symbol of the unknown?\",\n",
        "              # \"How does Melville’s narrative style in Moby Dick contribute to the sense of adventure and mystery?\",\n",
        "              # \"How does Ishmael’s perspective shape the reader’s understanding of the story in Moby Dick?\",\n",
        "              # \"How does Moby Dick reflect 19th-century views on fate and destiny?\",\n",
        "              # \"What philosophical questions does Melville raise about human existence and purpose in Moby Dick?\",\n",
        "              # \"How does Melville use imagery to depict the sea as both beautiful and terrifying in Moby Dick?\",\n",
        "              # \"How does Moby Dick describe the vastness and danger of the open sea?\",\n",
        "              # \"What moral dilemmas do the crew members face in Moby Dick?\",\n",
        "              # \"How does Moby Dick present Ahab's pursuit of revenge as both justified and self-destructive?\"\n",
        "              ]\n",
        "\n",
        "question = questions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tKuokc8HizW8",
      "metadata": {
        "id": "tKuokc8HizW8"
      },
      "source": [
        "## Indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LXOKovlBi2UT",
      "metadata": {
        "id": "LXOKovlBi2UT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "# there can be mulitple urls\n",
        "loader = WebBaseLoader(\"https://www.gutenberg.org/cache/epub/2701/pg2701.txt\")\n",
        "books = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pA3RMwUVi_LC",
      "metadata": {
        "id": "pA3RMwUVi_LC"
      },
      "source": [
        "### Splitting the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xKrm-uRXi6Y-",
      "metadata": {
        "id": "xKrm-uRXi6Y-"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50)\n",
        "\n",
        "# Make splits\n",
        "splits = text_splitter.split_documents(books)\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1XG7zsLSjG2k",
      "metadata": {
        "id": "1XG7zsLSjG2k"
      },
      "source": [
        "\n",
        "### vectorize chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lJDCT94ejLMk",
      "metadata": {
        "id": "lJDCT94ejLMk"
      },
      "outputs": [],
      "source": [
        "from langchain_mistralai import MistralAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=MistralAIEmbeddings())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r6StrW5PjUFe",
      "metadata": {
        "id": "r6StrW5PjUFe"
      },
      "source": [
        "## Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DDBVswV-jfcj",
      "metadata": {
        "id": "DDBVswV-jfcj"
      },
      "source": [
        "### Init Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hfav_yuTjSpm",
      "metadata": {
        "id": "Hfav_yuTjSpm"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76f1b6c5-faa9-404b-90c6-22d3b40169fa",
      "metadata": {
        "id": "76f1b6c5-faa9-404b-90c6-22d3b40169fa"
      },
      "source": [
        "### Sub-questions Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "965de464-0c98-4318-9f9e-f8a597c8d5d6",
      "metadata": {
        "id": "965de464-0c98-4318-9f9e-f8a597c8d5d6"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Multi Query: Different Perspectives\n",
        "template = \"\"\"You are a helpful assistant designed to generate multiple sub-questions related to an input question.\n",
        "Your goal is to break down the main question into distinct sub-problems that can be answered individually.\n",
        "Generate three related search queries based on: {question} and output each query on a new line.\"\"\"\n",
        "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "generate_queries = (\n",
        "    prompt_perspectives\n",
        "    | ChatMistralAI(temperature=0)\n",
        "    | StrOutputParser()\n",
        "    | (lambda x: x.split(\"\\n\"))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VB1ZfXSjyQrA",
      "metadata": {
        "id": "VB1ZfXSjyQrA"
      },
      "source": [
        "### Output original questions and their detailized sub-questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iTjaQ_4bnY5t",
      "metadata": {
        "id": "iTjaQ_4bnY5t"
      },
      "outputs": [],
      "source": [
        "for question in questions:\n",
        "    print(\"-------------\")\n",
        "    print(question)\n",
        "    sub_problems = generate_queries.invoke({\"question\":question})\n",
        "    for sub_problem in sub_problems:\n",
        "        print(\"\\t\"+sub_problem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f253520-386f-434b-8daa-d6dadb89eddb",
      "metadata": {
        "id": "4f253520-386f-434b-8daa-d6dadb89eddb"
      },
      "outputs": [],
      "source": [
        "from langchain.load import dumps, loads\n",
        "\n",
        "def get_unique_union(documents: list[list]):\n",
        "    \"\"\" Unique union of retrieved docs \"\"\"\n",
        "    # Flatten list of lists, and convert each Document to string\n",
        "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
        "    # Get unique documents\n",
        "    unique_docs = list(set(flattened_docs))\n",
        "    # Return\n",
        "    return [loads(doc) for doc in unique_docs]\n",
        "\n",
        "# Retrieve\n",
        "\n",
        "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
        "docs = retrieval_chain.invoke({\"question\":question})\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dQtKADFvxzNP",
      "metadata": {
        "id": "dQtKADFvxzNP"
      },
      "source": [
        "# Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6e74e8-ddae-4165-9e4b-0022ac125194",
      "metadata": {
        "id": "af6e74e8-ddae-4165-9e4b-0022ac125194"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# RAG\n",
        "template = \"\"\"Answer the following question based on this context:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "llm = ChatMistralAI(temperature=0)\n",
        "\n",
        "final_rag_chain = (\n",
        "    {\"context\": retrieval_chain,\n",
        "     \"question\": itemgetter(\"question\")}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "for question in questions:\n",
        "    print(\"-------------\")\n",
        "    print(question)\n",
        "    rephrased_questions = generate_queries.invoke({\"question\":question})\n",
        "    for rephrased_question in rephrased_questions:\n",
        "        print(\"\\t\"+rephrased_question)\n",
        "    print(\"\\nAnswer: \")\n",
        "    print(final_rag_chain.invoke({\"question\":question}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GyoRf-6komAi",
      "metadata": {
        "id": "GyoRf-6komAi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
