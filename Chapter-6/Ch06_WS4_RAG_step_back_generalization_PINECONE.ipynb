{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Joq7ORdChec4",
      "metadata": {
        "id": "Joq7ORdChec4"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df89be8f-2c49-4f4f-9503-2bff0b08a67a",
      "metadata": {
        "collapsed": true,
        "id": "df89be8f-2c49-4f4f-9503-2bff0b08a67a"
      },
      "outputs": [],
      "source": [
        "! pip install langchain_community langchain_mistralai langchainhub langchain tiktoken langchain-pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5258de38-0cc0-4d9d-a5ca-6e750ebe6976",
      "metadata": {
        "id": "5258de38-0cc0-4d9d-a5ca-6e750ebe6976"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY'] = '<your LangChain API KEY goes here>'\n",
        "os.environ['MISTRAL_API_KEY'] = '<your Mistral API KEY goes here>'\n",
        "os.environ['HF_TOKEN'] = '<your Hugging Face TOKEN goes here>'\n",
        "os.environ['PINECONE_API_KEY'] = '<your Pinecone API KEY goes here>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ewAi5bmohmgP",
      "metadata": {
        "id": "ewAi5bmohmgP"
      },
      "outputs": [],
      "source": [
        "questions = [ \"What does Moby Dick say about humanity's struggle against nature?\",\n",
        "              \"How does Moby Dick explore the theme of obsession through Ahab's quest?\",\n",
        "              \"How is Captain Ahab portrayed as both a hero and a villain in Moby Dick?\",\n",
        "              # \"What motivates Ishmael to join the Pequod, and how does he change throughout the novel?\",\n",
        "              # \"What does the white whale symbolize in Moby Dick, and how does it relate to Ahab's obsession?\",\n",
        "              # \"How does the novel Moby Dick use the ocean as a symbol of the unknown?\",\n",
        "              # \"How does Melville’s narrative style in Moby Dick contribute to the sense of adventure and mystery?\",\n",
        "              # \"How does Ishmael’s perspective shape the reader’s understanding of the story in Moby Dick?\",\n",
        "              # \"How does Moby Dick reflect 19th-century views on fate and destiny?\",\n",
        "              # \"What philosophical questions does Melville raise about human existence and purpose in Moby Dick?\",\n",
        "              # \"How does Melville use imagery to depict the sea as both beautiful and terrifying in Moby Dick?\",\n",
        "              # \"How does Moby Dick describe the vastness and danger of the open sea?\",\n",
        "              # \"What moral dilemmas do the crew members face in Moby Dick?\",\n",
        "              # \"How does Moby Dick present Ahab's pursuit of revenge as both justified and self-destructive?\"\n",
        "              ]\n",
        "\n",
        "question = questions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tKuokc8HizW8",
      "metadata": {
        "id": "tKuokc8HizW8"
      },
      "source": [
        "## Indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LXOKovlBi2UT",
      "metadata": {
        "id": "LXOKovlBi2UT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "# there can be mulitple urls\n",
        "loader = WebBaseLoader(\"https://www.gutenberg.org/cache/epub/2701/pg2701.txt\")\n",
        "books = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pA3RMwUVi_LC",
      "metadata": {
        "id": "pA3RMwUVi_LC"
      },
      "source": [
        "### Splitting the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xKrm-uRXi6Y-",
      "metadata": {
        "id": "xKrm-uRXi6Y-"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50)\n",
        "\n",
        "# Make splits\n",
        "splits = text_splitter.split_documents(books)\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1XG7zsLSjG2k",
      "metadata": {
        "id": "1XG7zsLSjG2k"
      },
      "source": [
        "### Indexing to PineconeDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lJDCT94ejLMk",
      "metadata": {
        "id": "lJDCT94ejLMk"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone\n",
        "from langchain_mistralai import MistralAIEmbeddings\n",
        "# Notlangchain_community.vectorstores\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "# Initialize Pinecone client\n",
        "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
        "index = pc.Index(\"book-passages\")\n",
        "\n",
        "# Create LangChain vectorstore\n",
        "vectorstore = PineconeVectorStore(\n",
        "    index=index,\n",
        "    embedding=MistralAIEmbeddings(),\n",
        "    text_key=\"text\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r6StrW5PjUFe",
      "metadata": {
        "id": "r6StrW5PjUFe"
      },
      "source": [
        "## Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DDBVswV-jfcj",
      "metadata": {
        "id": "DDBVswV-jfcj"
      },
      "source": [
        "### Init Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hfav_yuTjSpm",
      "metadata": {
        "id": "Hfav_yuTjSpm"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76f1b6c5-faa9-404b-90c6-22d3b40169fa",
      "metadata": {
        "id": "76f1b6c5-faa9-404b-90c6-22d3b40169fa"
      },
      "source": [
        "### Step-Back Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "965de464-0c98-4318-9f9e-f8a597c8d5d6",
      "metadata": {
        "id": "965de464-0c98-4318-9f9e-f8a597c8d5d6"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "generification_play = [\n",
        "    {\n",
        "        \"input\": \"What are the economic impacts of tourism in Venice?\",\n",
        "        \"output\": \"How does tourism affect local economies in popular cities?\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"What are the main causes of air pollution in New Delhi?\",\n",
        "        \"output\": \"What are the common causes of air pollution in large cities?\",\n",
        "    },\n",
        "]\n",
        "# We now transform these to example messages\n",
        "play_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"ai\", \"{output}\"),\n",
        "    ]\n",
        ")\n",
        "play_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=play_prompt_template,\n",
        "    examples=generification_play,\n",
        ")\n",
        "stepback_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "\"\"\"\n",
        "You are a knowledgeable assistant.\n",
        "Your task is to transform specific questions into broader,\n",
        "more general questions that are easier to answer and provide a wider perspective.\n",
        "This approach is known as creating 'step-back' questions.\n",
        "Here are a few examples:\n",
        "\"\"\",\n",
        "        ),\n",
        "        # Play Prompt\n",
        "        play_prompt,\n",
        "        # Genuine user question\n",
        "        (\"user\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8tGzKf76yAK2",
      "metadata": {
        "id": "8tGzKf76yAK2"
      },
      "source": [
        "### Output original questions and their step-back questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iTjaQ_4bnY5t",
      "metadata": {
        "id": "iTjaQ_4bnY5t"
      },
      "outputs": [],
      "source": [
        "from langchain_mistralai import ChatMistralAI\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "stepback_chain = stepback_prompt | ChatMistralAI(temperature=0) | StrOutputParser()\n",
        "\n",
        "for question in questions:\n",
        "    print(\"-------------\")\n",
        "    print(\"Original Question:\\n\\t\"+question)\n",
        "    stepback_question = stepback_chain.invoke({\"question\":question})\n",
        "    print(\"Generic question:\\n\\t\"+stepback_question)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hDf3INz_x5RP",
      "metadata": {
        "id": "hDf3INz_x5RP"
      },
      "source": [
        "# Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GyoRf-6komAi",
      "metadata": {
        "id": "GyoRf-6komAi"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "\n",
        "response_prompt_template = \"\"\"\n",
        "You are a world knowledge expert.\n",
        "Answer the following question thoroughly.\n",
        "Use relevant information from the provided context but disregard any irrelevant details.\n",
        "\n",
        "Context:\n",
        "{normal_context}\n",
        "{step_back_context}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
        "\n",
        "chain = (\n",
        "    {\n",
        "        # Retrieve context using the normal question\n",
        "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
        "        # Retrieve context using the step-back question\n",
        "        \"step_back_context\": stepback_chain | retriever,\n",
        "        # Pass on the question\n",
        "        \"question\": lambda x: x[\"question\"],\n",
        "    }\n",
        "    | response_prompt\n",
        "    | ChatMistralAI(temperature=0)\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain.invoke({\"question\": question})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
