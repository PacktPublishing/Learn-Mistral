{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZF-DduytjPh0"
      },
      "outputs": [],
      "source": [
        "!pip install mistralai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mistral Client Intialization"
      ],
      "metadata": {
        "id": "IbowB8Qr_MMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mistralai import Mistral\n",
        "from google.colab import userdata\n",
        "\n",
        "# Instantiate the MistralClient to create a client object\n",
        "client = Mistral(userdata.get(\"MISTRAL_API_KEY\"))\n",
        "\n",
        "\n",
        "# Use the client object to list all available models\n",
        "models = client.models.list()\n",
        "\n",
        "# Iterate over the list of models and print each one on a new line\n",
        "for model in models.data:\n",
        "    print(model.id)\n"
      ],
      "metadata": {
        "id": "vqFzNHe7kDQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculation of embedding"
      ],
      "metadata": {
        "id": "bIRIWNnF_Ulj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = \"A young wizard fights evil.\"\n",
        "sample_embed = client.embeddings.create(model='mistral-embed', inputs=[sample_sentence])\n",
        "clean_sample_embed =  sample_embed.data[0].embedding\n",
        "print(len(clean_sample_embed))\n",
        "print(clean_sample_embed[:10])"
      ],
      "metadata": {
        "id": "XTsZZqSqvlmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic search with cosine similarity"
      ],
      "metadata": {
        "id": "x0_ohi99_fos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dish_descriptions = [\n",
        "    \"Grilled steak with garlic butter\",       # Meat\n",
        "    \"Seared salmon with lemon dill sauce\",    # Fish\n",
        "    \"Roasted vegetable medley with herbs\",    # Veggie\n",
        "    \"Spicy tofu stir-fry with vegetables\",    # Asian\n",
        "    \"Tacos with spicy chicken and salsa\",     # Mexican\n",
        "    \"Spicy chili con carne with beans\",       # Spicy\n",
        "    \"Chocolate lava cake with vanilla ice cream\",  # Sweet\n",
        "    \"Creamy tomato basil soup\",               # Liquid\n",
        "    \"Cheeseburger with fries\",                # Fast\n",
        "    \"Seared scallops with truffle oil\",       # Fine\n",
        "]\n",
        "\n",
        "dish_embeds = client.embeddings.create(model='mistral-embed', inputs=dish_descriptions)\n",
        "dish_embeds_arr = []\n",
        "\n",
        "\n",
        "for embed in dish_embeds.data:\n",
        "  dish_embeds_arr.append(embed.embedding)\n",
        "\n",
        "print(len(dish_embeds_arr))\n",
        "print(len(dish_embeds_arr[0]))"
      ],
      "metadata": {
        "id": "nnM3YERjlnA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_embed = []\n",
        "\n",
        "for embed in dish_embeds.data:\n",
        "  clean_embed.append(embed.embedding)\n",
        "\n",
        "print(clean_embed[2][:10])\n"
      ],
      "metadata": {
        "id": "HBSp2lG-nC22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = input(\"What do you prefer for dinner? \")\n",
        "user_embed = client.embeddings.create(model='mistral-embed', inputs=[user_input]).data[0].embedding\n",
        "user_embed[:10]"
      ],
      "metadata": {
        "id": "Ybb-yncCpVGG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "print (1 - cosine(user_embed, dish_embeds_arr[0]))\n",
        "print (1 - cosine(user_embed, dish_embeds_arr[1]))\n",
        "print (1 - cosine(user_embed, dish_embeds_arr[2]))"
      ],
      "metadata": {
        "id": "RrRp1bNHMnBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine, cdist\n",
        "import numpy as np\n",
        "\n",
        "distances = cdist(np.array(user_embed).reshape(1, -1), dish_embeds_arr, \"cosine\")\n",
        "\n",
        "mostRelevant = np.argmin(distances) #index of the most relevant movie\n",
        "\n",
        "print(f\"most relevant index: {mostRelevant}\")\n",
        "print(f\"Then you might find tasty: {dish_descriptions[mostRelevant]}\")\n"
      ],
      "metadata": {
        "id": "sw8Zh6MRpncU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pinecone storage and semantic search"
      ],
      "metadata": {
        "id": "sVrI6Uxy-38n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone"
      ],
      "metadata": {
        "id": "ca0CyUFHsoJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pcone = Pinecone(api_key=userdata.get(\"PINECONE_API_KEY\"))\n"
      ],
      "metadata": {
        "id": "gtevUNizss2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "existing_indexes = pcone.list_indexes()\n",
        "existing_index_names = [index.name for index in existing_indexes]\n",
        "\n",
        "# Check and delete sich index if it already exist\n",
        "if 'dish-embeddings' in existing_index_names:\n",
        "  pcone.delete_index('dish-embeddings')\n",
        "# Create fresh index\n",
        "pcone.create_index(\n",
        "  name='dish-embeddings', dimension=1024, metric='cosine',\n",
        "  spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
        ")\n"
      ],
      "metadata": {
        "id": "26tpZmy3tqp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = pcone.Index('dish-embeddings')"
      ],
      "metadata": {
        "id": "VUNZ_-pbue7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, embed in enumerate(dish_embeds_arr):\n",
        "    index.upsert([(f'dish_{i}', embed)])"
      ],
      "metadata": {
        "id": "M_WIGqV9unnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = index.query(vector=[user_embed], top_k=1)\n",
        "closest_dish_id = result['matches'][0]['id']\n",
        "print(closest_dish_id)\n",
        "closest_dish_index = int(closest_dish_id.split('_')[1])\n",
        "print(closest_dish_index)\n",
        "print(dish_descriptions[closest_dish_index])"
      ],
      "metadata": {
        "id": "IsK-u9cLvGET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heat map Visualization"
      ],
      "metadata": {
        "id": "DAVNReGe-xQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Define the sentences and words\n",
        "sentence1 = [\"I\", \"enjoy\", \"spicy\", \"food\"]\n",
        "sentence2 = [\"She\", \"likes\", \"hot\", \"meals\"]\n",
        "\n",
        "# Generate embeddings for each word\n",
        "embeddings1 = client.embeddings.create(model='mistral-embed', inputs=sentence1)\n",
        "embeddings2 = client.embeddings.create(model='mistral-embed', inputs=sentence2)\n",
        "\n",
        "# Clean embed arrays\n",
        "embeddings1_arr = []\n",
        "embeddings2_arr = []\n",
        "\n",
        "for embed in embeddings1.data:\n",
        "  embeddings1_arr.append(embed.embedding)\n",
        "\n",
        "for embed in embeddings2.data:\n",
        "  embeddings2_arr.append(embed.embedding)\n",
        "\n",
        "\n",
        "# Compute cosine similarity between each pair of words\n",
        "similarity_scores = cosine_similarity(embeddings2_arr, embeddings1_arr)\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(similarity_scores, annot=True, cmap='Blues', xticklabels=sentence1, yticklabels=sentence2)\n",
        "\n",
        "# Set titles and labels\n",
        "plt.title('Semantic Similarity Heatmap')\n",
        "plt.xlabel('Words in Sentence 1')\n",
        "plt.ylabel('Words in Sentence 2')\n",
        "\n",
        "# Show the heatmap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AsWSqpwDvZuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## t-SNE Visualizations"
      ],
      "metadata": {
        "id": "qns9QIIvFHG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Define the sentences and words\n",
        "sentence1 = [\"I\", \"enjoy\", \"spicy\", \"food\"]\n",
        "sentence2 = [\"She\", \"likes\", \"hot\", \"meals\"]\n",
        "\n",
        "# Generate embeddings for each word\n",
        "embeddings1 = client.embeddings.create(model='mistral-embed', inputs=sentence1)\n",
        "embeddings2 = client.embeddings.create(model='mistral-embed', inputs=sentence2)\n",
        "\n",
        "# Clean embed arrays\n",
        "embeddings1_arr = []\n",
        "embeddings2_arr = []\n",
        "\n",
        "for embed in embeddings1.data:\n",
        "    embeddings1_arr.append(embed.embedding)\n",
        "\n",
        "for embed in embeddings2.data:\n",
        "    embeddings2_arr.append(embed.embedding)\n",
        "\n",
        "# Combine embeddings and create labels\n",
        "combined_embeddings = np.array(embeddings1_arr + embeddings2_arr)\n",
        "labels = sentence1 + sentence2\n",
        "\n",
        "# Use t-SNE to reduce dimensions to 2D\n",
        "tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
        "tsne_results = tsne.fit_transform(combined_embeddings)\n",
        "\n",
        "# Plot the t-SNE results\n",
        "plt.figure(figsize=(10, 7))\n",
        "for i, label in enumerate(labels):\n",
        "    x, y = tsne_results[i, :]\n",
        "    plt.scatter(x, y)\n",
        "    plt.text(x+0.1, y+0.1, label, fontsize=12)\n",
        "\n",
        "plt.title('t-SNE Visualization of Word Embeddings')\n",
        "plt.xlabel('t-SNE Dimension 1')\n",
        "plt.ylabel('t-SNE Dimension 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KQf2fhbBrFx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "dish_embeds_arr.append(user_embed)\n",
        "dish_descriptions.append(user_input)\n",
        "\n",
        "dish_embeds_np_arr = np.array(dish_embeds_arr)\n",
        "# Use t-SNE to reduce dimensions to 2D\n",
        "tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
        "tsne_results = tsne.fit_transform(dish_embeds_np_arr)\n",
        "\n",
        "# Plot the t-SNE results\n",
        "plt.figure(figsize=(10, 7))\n",
        "for i, label in enumerate(dish_descriptions):\n",
        "    x, y = tsne_results[i, :]\n",
        "    plt.scatter(x, y)\n",
        "    plt.text(x + 0.1, y + 0.1, label, fontsize=9)\n",
        "\n",
        "plt.title('t-SNE Visualization of Dish Embeddings')\n",
        "plt.xlabel('t-SNE Dimension 1')\n",
        "plt.ylabel('t-SNE Dimension 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mD5jglcfuieb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}