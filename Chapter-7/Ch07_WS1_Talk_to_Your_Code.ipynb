{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNXOWt2R-1x4"
      },
      "source": [
        "# Talk to your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osDa8_mzJk2C"
      },
      "source": [
        "#Step 01: Install All the Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "by9_WiR7IhFv"
      },
      "outputs": [],
      "source": [
        "!pip install openai tiktoken chromadb langchain langchain_mistralai langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QryMudLjKy-E"
      },
      "outputs": [],
      "source": [
        "!pip install GitPython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqaNhoWsJ1PF"
      },
      "source": [
        "# Step 02: Initialize API keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz1JKOWtJtuZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "os.environ['MISTRAL_API_KEY'] = '<your Mistral API KEY goes here>'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_UCYeVxLGtr"
      },
      "source": [
        "# Step 03: Clone the LangChain Github Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-v8Usdftx6B"
      },
      "outputs": [],
      "source": [
        "#!rm -rf test_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyBOoIDlLVBo"
      },
      "outputs": [],
      "source": [
        "!mkdir test_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsBti-sGKmVV"
      },
      "outputs": [],
      "source": [
        "from git import Repo\n",
        "\n",
        "repo_path = \"/content/test_repo\"\n",
        "\n",
        "repo = Repo.clone_from(\"https://github.com/langchain-ai/langchain\", to_path=repo_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPbmZY-eL51T"
      },
      "source": [
        "# Step 04: Load the Data from the Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CshMDoa7LOfD"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import Language\n",
        "from langchain.document_loaders.generic import GenericLoader\n",
        "from langchain.document_loaders.parsers import LanguageParser\n",
        "\n",
        "\n",
        "loader = GenericLoader.from_filesystem(\n",
        "    repo_path+'/libs/langchain/langchain',\n",
        "    glob = \"**/*\",\n",
        "    suffixes=[\".py\"],\n",
        "    parser = LanguageParser(\n",
        "        language=Language.PYTHON, \n",
        "        parser_threshold=500\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T93X1D_qMJos"
      },
      "outputs": [],
      "source": [
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL4N0gRTMigP"
      },
      "outputs": [],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-dHilmLMk7-"
      },
      "outputs": [],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO6IJH0sNHYr"
      },
      "source": [
        "# Step 05: Split the Document into Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDDUMNAcMmWC"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "documents_splitter = RecursiveCharacterTextSplitter.from_language(language = Language.PYTHON,\n",
        "                                                             chunk_size = 2000,\n",
        "                                                             chunk_overlap = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ol6eRiuNNplM"
      },
      "outputs": [],
      "source": [
        "texts = documents_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC85oDiENzjD"
      },
      "outputs": [],
      "source": [
        "len(texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKRgzXdqPeDZ"
      },
      "source": [
        "# Step 06: Download the MistralAI Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvoxmidZQmBi"
      },
      "outputs": [],
      "source": [
        "from langchain_mistralai import MistralAIEmbeddings\n",
        "embeddings=MistralAIEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8pAFIKeSf4C"
      },
      "source": [
        "# Step 07: Setting Up Chroma as out Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F92caqIRy4C"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "vectordb = Chroma.from_documents(texts, embedding=embeddings, persist_directory='./data')\n",
        "vectordb.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIxIspWaTuZJ"
      },
      "source": [
        "# Step 08: Creating an OpenAI Model Warpper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIZaATJHS0b_"
      },
      "outputs": [],
      "source": [
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "llm = ChatMistralAI(\n",
        "    model_name=\"mistral-large-latest\",\n",
        "    temperature=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HthbColvWX0u"
      },
      "outputs": [],
      "source": [
        "llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCW-X_W9T4UC"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationSummaryMemory\n",
        "\n",
        "memory = ConversationSummaryMemory(llm=llm, memory_key = \"chat_history\", return_messages=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8Ww86NGUMXi"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(llm, retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\":8}), memory=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eMoZfLoVNV-"
      },
      "source": [
        "# Talk to Your Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbGp_zcxU76v"
      },
      "outputs": [],
      "source": [
        "question = \"How i can initialize the ReAct Agent\"\n",
        "result = qa(question)\n",
        "print(\"Answer:\", result['answer'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tsFAgTAWS-b"
      },
      "outputs": [],
      "source": [
        "question = \"What is the class hierarchy for ReActDocstoreAgent?\"\n",
        "result = qa(question)\n",
        "print(result['answer'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
